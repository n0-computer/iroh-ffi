/* tslint:disable */
/* eslint-disable */

/* auto-generated by NAPI-RS */

/** The Hash and associated tag of a newly created collection */
export interface HashAndTag {
  /** The hash of the collection */
  hash: string
  /** The tag of the collection */
  tag: Array<number>
}
/** Outcome of a blob add operation. */
export interface BlobAddOutcome {
  /** The hash of the blob */
  hash: string
  /** The format the blob */
  format: BlobFormat
  /** The size of the blob */
  size: bigint
  /** The tag of the blob */
  tag: Array<number>
}
/** Whether to wrap the added data in a collection. */
export interface WrapOption {
  /** Wrap the file or directory in a colletion. */
  wrap: boolean
  /** Override the filename in the wrapping collection. */
  wrapOverride?: string
}
/** An AddProgress event indicating an item was found with name `name`, that can be referred to by `id` */
export interface AddProgressFound {
  /** A new unique id for this entry. */
  id: bigint
  /** The name of the entry. */
  name: string
  /** The size of the entry in bytes. */
  size: bigint
}
/** An AddProgress event indicating we got progress ingesting item `id`. */
export interface AddProgressProgress {
  /** The unique id of the entry. */
  id: bigint
  /** The offset of the progress, in bytes. */
  offset: bigint
}
/** An AddProgress event indicated we are done with `id` and now have a hash `hash` */
export interface AddProgressDone {
  /** The unique id of the entry. */
  id: bigint
  /** The hash of the entry. */
  hash: string
}
/** An AddProgress event indicating we are done with the the whole operation */
export interface AddProgressAllDone {
  /** The hash of the created data. */
  hash: string
  /** The format of the added data. */
  format: BlobFormat
  /** The tag of the added data. */
  tag: Array<number>
}
/** An AddProgress event indicating we got an error and need to abort */
export interface AddProgressAbort {
  error: string
}
/** Progress updates for the add operation. */
export interface AddProgress {
  /** An item was found with name `name`, from now on referred to via `id` */
  found?: AddProgressFound
  /** We got progress ingesting item `id`. */
  progress?: AddProgressProgress
  /** We are done with `id`, and the hash is `hash`. */
  done?: AddProgressDone
  /** We are done with the whole operation. */
  allDone?: AddProgressAllDone
  /**
   * We got an error and need to abort.
   *
   * This will be the last message in the stream.
   */
  abort?: AddProgressAbort
}
/** A format identifier */
/** Raw blob */
Raw = 'Raw',
/** A sequence of BLAKE3 hashes */
HashSeq = 'HashSeq'
/** The expected format of a hash being exported. */
/** The hash refers to any blob and will be exported to a single file. */
Blob = 'Blob',
/**
 * The hash refers to a [`crate::format::collection::Collection`] blob
 * and all children of the collection shall be exported to one file per child.
 *
 * If the blob can be parsed as a [`BlobFormat::HashSeq`], and the first child contains
 * collection metadata, all other children of the collection will be exported to
 * a file each, with their collection name treated as a relative path to the export
 * destination path.
 *
 * If the blob cannot be parsed as a collection, the operation will fail.
 */
Collection = 'Collection'
/**
 * The export mode describes how files will be exported.
 *
 * This is a hint to the import trait method. For some implementations, this
 * does not make any sense. E.g. an in memory implementation will always have
 * to copy the file into memory. Also, a disk based implementation might choose
 * to copy small files even if the mode is `Reference`.
 */
/**
 * This mode will copy the file to the target directory.
 *
 * This is the safe default because the file can not be accidentally modified
 * after it has been exported.
 */
Copy = 'Copy',
/**
 * This mode will try to move the file to the target directory and then reference it from
 * the database.
 *
 * This has a large performance and storage benefit, but it is less safe since
 * the file might be modified in the target directory after it has been exported.
 *
 * Stores are allowed to ignore this mode and always copy the file, e.g.
 * if the file is very small or if the store does not support referencing files.
 */
TryReference = 'TryReference'
/** A response to a list blobs request */
export interface BlobInfo {
  /** Location of the blob */
  path: string
  /** The hash of the blob */
  hash: string
  /** The size of the blob */
  size: bigint
}
/** A response to a list blobs request */
export interface IncompleteBlobInfo {
  /** The size we got */
  size: bigint
  /** The size we expect */
  expectedSize: bigint
  /** The hash of the blob */
  hash: string
}
/** A response to a list collections request */
export interface CollectionInfo {
  /** Tag of the collection */
  tag: Array<number>
  /** Hash of the collection */
  hash: string
  /**
   * Number of children in the collection
   *
   * This is an optional field, because the data is not always available.
   */
  totalBlobsCount?: bigint
  /**
   * Total size of the raw data referred to by all links
   *
   * This is an optional field, because the data is not always available.
   */
  totalBlobsSize?: bigint
}
/** Stats counter */
export interface CounterStats {
  /** The counter value */
  value: number
  /** The counter description */
  description: string
}
/** Information about a direct address. */
export interface DirectAddrInfo {
  /** The address reported. */
  addr: string
  /** The latency to the address, if any. */
  latency?: number
  /** Last control message received by this node. */
  lastControlTime?: number
  lastControlMsg?: string
  /** How long ago was the last payload message for this node. */
  lastPayload?: number
  /** When was this connection last alive, if ever. */
  lastAlive?: number
}
/** The latency and type of the control message */
export interface LatencyAndControlMsg {
  /** The latency of the control message. In milliseconds */
  latency: number
  /** The type of control message, represented as a string */
  controlMsg: string
}
/** Information about a connection */
export interface ConnectionInfo {
  /** The node identifier of the endpoint. Also a public key. */
  nodeId: Array<number>
  /** Relay url, if available. */
  relayUrl?: string
  /**
   * List of addresses at which this node might be reachable, plus any latency information we
   * have about that address and the last time the address was used.
   */
  addrs: Array<DirectAddrInfo>
  /** The type of connection we have to the peer, either direct or over relay. */
  connType: ConnectionType
  /** The latency of the `conn_type`. In milliseconds. */
  latency?: number
  /** Duration since the last time this peer was used. In milliseconds. */
  lastUsed?: number
}
/** The type of the connection */
/** Indicates you have a UDP connection. */
Direct = 'Direct',
/** Indicates you have a relayed connection. */
Relay = 'Relay',
/** Indicates you have an unverified UDP connection, and a relay connection for backup. */
Mixed = 'Mixed',
/** Indicates you have no proof of connection. */
None = 'None'
/** The type of connection we have to the node */
export interface ConnectionType {
  /** The type of connection. */
  type: ConnType
  /** Details of the actual connection, dependent on the type. */
  details?: string
}
/** A peer and it's addressing information. */
export interface NodeAddr {
  nodeId: string
  /** Get the home relay URL for this peer */
  relayUrl?: string
  /** Direct addresses of this peer. */
  addresses: Array<string>
}
/** Options passed to [`IrohNode.new`]. Controls the behaviour of an iroh node. */
export interface NodeOptions {
  /**
   * How frequently the blob store should clean up unreferenced blobs, in milliseconds.
   * Set to null to disable gc
   */
  gcIntervalMillis?: number
}
/** The response to a status request */
export interface NodeStatus {
  /** The node id and socket addresses of this node. */
  addr: NodeAddr
  /** The bound listening addresses of the node */
  listenAddrs: Array<string>
  /** The version of the node */
  version: string
  /** RPC address, if currently listening. */
  rpcAddr?: string
}
/** Options when creating a ticket */
/**
 * Only the Node ID is added.
 *
 * This usually means that iroh-dns discovery is used to find address information.
 */
Id = 'Id',
/** Include both the relay URL and the direct addresses. */
RelayAndAddresses = 'RelayAndAddresses',
/** Only include the relay URL. */
Relay = 'Relay',
/** Only include the direct addresses. */
Addresses = 'Addresses'
/** The logging level. See the rust (log crate)[https://docs.rs/log] for more information. */
Trace = 'Trace',
Debug = 'Debug',
Info = 'Info',
Warn = 'Warn',
Error = 'Error',
Off = 'Off'
/** Set the logging level. */
function setLogLevel(level: LogLevel): void
/** Initialize the global metrics collection. */
function startMetricsCollection(): void
/**
 * Helper function that translates a key that was derived from the [`path_to_key`] function back
 * into a path.
 *
 * If `prefix` exists, it will be stripped before converting back to a path
 * If `root` exists, will add the root as a parent to the created path
 * Removes any null byte that has been appened to the key
 */
function keyToPath(key: Array<number>, prefix?: string | undefined | null, root?: string | undefined | null): string
/**
 * Helper function that creates a document key from a canonicalized path, removing the `root` and adding the `prefix`, if they exist
 *
 * Appends the null byte to the end of the key.
 */
function pathToKey(path: string, prefix?: string | undefined | null, root?: string | undefined | null): Array<number>
/** Identifier for an [`Author`] */
export declare class AuthorId {
  /** Get an [`AuthorId`] from a String. */
  constructor(str: string)
  /** Returns true when both AuthorId's have the same value */
  equal(other: AuthorId): boolean
  toString(): string
}
/**
 * Author key to insert entries in a document
 *
 * Internally, an author is a `SigningKey` which is used to sign entries.
 */
export declare class Author {
  /** Get the [`AuthorId`] of this Author */
  id(): AuthorId
  toString(): string
}
/** Iroh authors client. */
export declare class Authors {
  /**
   * Returns the default document author of this node.
   *
   * On persistent nodes, the author is created on first start and its public key is saved
   * in the data directory.
   *
   * The default author can be set with [`Self::set_default`].
   */
  default(): Promise<AuthorId>
  /** List all the AuthorIds that exist on this node. */
  list(): Promise<Array<AuthorId>>
  /**
   * Create a new document author.
   *
   * You likely want to save the returned [`AuthorId`] somewhere so that you can use this author
   * again.
   *
   * If you need only a single author, use [`Self::default`].
   */
  create(): Promise<AuthorId>
  /**
   * Export the given author.
   *
   * Warning: This contains sensitive data.
   */
  export(author: AuthorId): Promise<Author>
  /**
   * Import the given author.
   *
   * Warning: This contains sensitive data.
   */
  import(author: Author): Promise<AuthorId>
  /**
   * Deletes the given author by id.
   *
   * Warning: This permanently removes this author.
   */
  delete(author: AuthorId): Promise<void>
}
/** Iroh blobs client. */
export declare class Blobs {
  /**
   * List all complete blobs.
   *
   * Note: this allocates for each `BlobListResponse`, if you have many `BlobListReponse`s this may be a prohibitively large list.
   * Please file an [issue](https://github.com/n0-computer/iroh-ffi/issues/new) if you run into this issue
   */
  list(): Promise<Array<Hash>>
  /**
   * Get the size information on a single blob.
   *
   * Method only exists in FFI
   */
  size(hash: string): Promise<bigint>
  /**
   * Read all bytes of single blob.
   *
   * This allocates a buffer for the full blob. Use only if you know that the blob you're
   * reading is small. If not sure, use [`Self::blobs_size`] and check the size with
   * before calling [`Self::blobs_read_to_bytes`].
   */
  readToBytes(hash: string): Promise<Array<number>>
  /**
   * Read all bytes of single blob at `offset` for length `len`.
   *
   * This allocates a buffer for the full length `len`. Use only if you know that the blob you're
   * reading is small. If not sure, use [`Self::blobs_size`] and check the size with
   * before calling [`Self::blobs_read_at_to_bytes`].
   */
  readAtToBytes(hash: string, offset: bigint, len?: bigint | undefined | null): Promise<Array<number>>
  /**
   * Import a blob from a filesystem path.
   *
   * `path` should be an absolute path valid for the file system on which
   * the node runs.
   * If `in_place` is true, Iroh will assume that the data will not change and will share it in
   * place without copying to the Iroh data directory.
   */
  addFromPath(path: string, inPlace: boolean, tag: SetTagOption, wrap: WrapOption, cb: (err: Error | null, arg: AddProgress) => unknown): Promise<void>
  /**
   * Export the blob contents to a file path
   * The `path` field is expected to be the absolute path.
   */
  writeToPath(hash: string, path: string): Promise<void>
  /** Write a blob by passing bytes. */
  addBytes(bytes: Array<number>): Promise<BlobAddOutcome>
  /** Write a blob by passing bytes, setting an explicit tag name. */
  addBytesNamed(bytes: Array<number>, name: string): Promise<BlobAddOutcome>
  /**
   * Export a blob from the internal blob store to a path on the node's filesystem.
   *
   * `destination` should be a writeable, absolute path on the local node's filesystem.
   *
   * If `format` is set to [`ExportFormat::Collection`], and the `hash` refers to a collection,
   * all children of the collection will be exported. See [`ExportFormat`] for details.
   *
   * The `mode` argument defines if the blob should be copied to the target location or moved out of
   * the internal store into the target location. See [`ExportMode`] for details.
   */
  export(hash: string, destination: string, format: BlobExportFormat, mode: BlobExportMode): Promise<void>
  /** Create a ticket for sharing a blob from this node. */
  share(hash: string, blobFormat: BlobFormat, ticketOptions: AddrInfoOptions): Promise<string>
  /**
   * List all incomplete (partial) blobs.
   *
   * Note: this allocates for each `BlobListIncompleteResponse`, if you have many `BlobListIncompleteResponse`s this may be a prohibitively large list.
   * Please file an [issue](https://github.com/n0-computer/iroh-ffi/issues/new) if you run into this issue
   */
  listIncomplete(): Promise<Array<IncompleteBlobInfo>>
  /**
   * List all collections.
   *
   * Note: this allocates for each `BlobListCollectionsResponse`, if you have many `BlobListCollectionsResponse`s this may be a prohibitively large list.
   * Please file an [issue](https://github.com/n0-computer/iroh-ffi/issues/new) if you run into this issue
   */
  listCollections(): Promise<Array<CollectionInfo>>
  /** Read the content of a collection */
  getCollection(hash: string): Promise<Collection>
  /**
   * Create a collection from already existing blobs.
   *
   * To automatically clear the tags for the passed in blobs you can set
   * `tags_to_delete` on those tags, and they will be deleted once the collection is created.
   */
  createCollection(collection: Collection, tag: SetTagOption, tagsToDelete: Array<string>): Promise<HashAndTag>
  /** Delete a blob. */
  deleteBlob(hash: string): Promise<void>
}
/** An option for commands that allow setting a Tag */
export declare class SetTagOption {
  /** A tag will be automatically generated */
  readonly auto: boolean
  /** The tag is explicitly vecnamed */
  readonly name?: Array<number>
  /** Indicate you want an automatically generated tag */
  static auto(): SetTagOption
  /** Indicate you want a named tag */
  static named(tag: Array<number>): SetTagOption
}
/** Hash type used throughout Iroh. A blake3 hash. */
export declare class Hash {
  /** The base32 representation of the hash. */
  readonly value: string
  /** Calculate the hash of the provide bytes. */
  constructor(buf: Array<number>)
  /** Create a `Hash` from its raw bytes representation. */
  static fromBytes(bytes: Array<number>): Hash
  /** Make a Hash from base32 or hex string */
  static fromString(s: string): this
}
/** Options to download  data specified by the hash. */
export declare class BlobDownloadOptions {
  /** Create a BlobDownloadRequest */
  constructor(format: BlobFormat, node: NodeAddr, tag: SetTagOption)
}
/** A chunk range specification as a sequence of chunk offsets */
export declare class RangeSpec {
  /** Checks if this [`RangeSpec`] does not select any chunks in the blob */
  isEmpty(): boolean
  /** Check if this [`RangeSpec`] selects all chunks in the blob */
  isAll(): boolean
}
/** A collection of blobs */
export declare class Collection { }
/**
 * A public key.
 *
 * The key itself is just a 32 byte array, but a key has associated crypto
 * information that is cached for performance reasons.
 */
export declare class PublicKey {
  /** Returns true if the PublicKeys are equal */
  equal(other: PublicKey): boolean
  /** Express the PublicKey as a byte array */
  toBytes(): Array<number>
  /** Make a PublicKey from base32 string */
  constructor(s: string)
  /**
   * Convert to a base32 string limited to the first 10 bytes for a friendly string
   * representation of the key.
   */
  fmtShort(): string
  /** Converts the public key into base32 string. */
  toString(): string
}
/** An Iroh node. Allows you to sync, store, and transfer data. */
export declare class Iroh {
  /** Access to authors specific funtionaliy. */
  get authors(): Authors
  /** Access to blob specific funtionaliy. */
  get blobs(): Blobs
  /**
   * Create a new iroh node.
   *
   * The `path` param should be a directory where we can store or load
   * iroh data from a previous session.
   */
  static persistent(path: string, opts?: NodeOptions | undefined | null): Promise<Iroh>
  /**
   * Create a new iroh node.
   *
   * All data will be only persistet in memory.
   */
  static memory(opts?: NodeOptions | undefined | null): Promise<Iroh>
  /** Access to node specific funtionaliy. */
  get node(): Node
}
/** Iroh node client. */
export declare class Node {
  /** Get statistics of the running node. */
  stats(): Promise<Record<string, CounterStats>>
  /** Return `ConnectionInfo`s for each connection we have to another iroh node. */
  connections(): Promise<Array<ConnectionInfo>>
  /** Return connection information on the currently running node. */
  connectionInfo(nodeId: PublicKey): Promise<ConnectionInfo | null>
  /** Get status information about a node */
  status(): Promise<NodeStatus>
  /** The string representation of the PublicKey of this node. */
  nodeId(): Promise<string>
  /** Return the [`NodeAddr`] for this node. */
  nodeAddr(): Promise<NodeAddr>
  /** Add a known node address to the node. */
  addNodeAddr(addr: NodeAddr): Promise<void>
  /** Get the relay server we are connected to. */
  homeRelay(): Promise<string | null>
  /** Shutdown this iroh node. */
  shutdown(force: boolean): Promise<void>
  /** Returns `Some(addr)` if an RPC endpoint is running, `None` otherwise. */
  myRpcAddr(): string | null
}
/**
 * A token containing everything to get a file from the provider.
 *
 * It is a single item which can be easily serialized and deserialized.
 */
export declare class BlobTicket {
  constructor(str: string)
  /** The hash of the item this ticket can retrieve. */
  hash(): Hash
  /** The [`NodeAddr`] of the provider for this ticket. */
  nodeAddr(): NodeAddr
  /** The [`BlobFormat`] for this ticket. */
  format(): BlobFormat
  /** True if the ticket is for a collection and should retrieve all blobs in it. */
  recursive(): boolean
  /** Convert this ticket into input parameters for a call to blobs_download */
  asDownloadOptions(): BlobDownloadOptions
}
